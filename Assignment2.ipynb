{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making list of all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1 = \"./Dataset/train/neg/\"\n",
    "dir2 = \"./Dataset/train/pos/\"\n",
    "dir3 = \"./Dataset/test/neg/\"\n",
    "dir4 = \"./Dataset/test/pos/\"\n",
    "train_neg = os.listdir(dir1)\n",
    "train_pos = os.listdir(dir2)\n",
    "test_neg = os.listdir(dir3)\n",
    "test_pos = os.listdir(dir4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making list of Positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir5 = \"./Dataset/negative-words.txt\"\n",
    "dir6 = \"./Dataset/positive-words.txt\"\n",
    "f_5= open(dir5, \"r\", encoding = \"latin-1\")\n",
    "f_6 = open(dir6, \"r\")\n",
    "neg_words  = f_5.read()\n",
    "pos_words = f_6.read()\n",
    "neg_words = neg_words.split()\n",
    "pos_words = pos_words.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileread(dir_, filenames, pos_words, neg_words) :\n",
    "    ret = []\n",
    "    for i,val in enumerate(filenames) :\n",
    "        #print(i)\n",
    "        f = open(dir_+filenames[i], \"r\")\n",
    "        data = f.read()\n",
    "        data = data.lower()\n",
    "        words = data.split()\n",
    "        count = len(words)\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        x_5 = 0\n",
    "        x_6 = 0\n",
    "        for j in words :\n",
    "            if j in pos_words :\n",
    "                pos_count+=1\n",
    "            if j in neg_words :\n",
    "                neg_count+=1\n",
    "            if j == 'no':\n",
    "                x_5 = 1\n",
    "            if j == '!' :\n",
    "                x_6 = 1\n",
    "        string = filenames[i].split('_')\n",
    "        rating = int(string[1].split('.')[0])\n",
    "        temp = [pos_count, neg_count, rating, math.log(count), x_5, x_6]\n",
    "        ret.append(temp)\n",
    "        \n",
    "    return ret\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing all files \n",
    "### Reading 10000 training and 2000 test files as otherwise they were taking too much time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_pd = fileread(dir1, train_neg[0:5000], pos_words, neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_labels = [0]*5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_pd = fileread(dir2, train_pos[0:5000], pos_words, neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_labels = [1]*5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neg_pd = fileread(dir3, test_neg[0:1000], pos_words, neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neg_labels = [0]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_pd = fileread(dir4, test_pos[0:1000], pos_words, neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_labels = [1]*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(inp) :\n",
    "    return (1/(1+np.exp(inp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CEL(y, y_hat) :\n",
    "    loss = 0\n",
    "    for i, val in enumerate(y):\n",
    "        try :\n",
    "            temp = -((y[i]*math.log(y_hat[0][i]))+((1-y[i])*math.log(1-y_hat[0][i])))\n",
    "            loss+= 0.0001*temp\n",
    "        except :\n",
    "            continue\n",
    "            #print(y_hat[0][i])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_neg_pd + train_pos_pd\n",
    "train_labels = train_neg_labels + train_pos_labels\n",
    "c = list(zip(train_data, train_labels))\n",
    "random.shuffle(c)\n",
    "x, y = zip(*c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train_data, weights):\n",
    "    length = len(train_data)\n",
    "    train_data = np.array(train_data).reshape(length, 6)\n",
    "    z = np.dot(train_data, np.transpose(weights))\n",
    "    return sigmoid(-z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight update Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_update(x,y, y_hat, lr = 0.0001 ) :\n",
    "    for i,val in enumerate(x) :\n",
    "        global weights\n",
    "        delta_w = np.multiply([y_hat[0][i]-y[i]],x[i])\n",
    "        weights -= lr*delta_w "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight updtae stochastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_update_stochastic(x,y, lr = 0.0001 ) :\n",
    "    length = len(x)\n",
    "    for i in range(length):\n",
    "        global weights_stochastic\n",
    "        z = np.dot(x[i], np.transpose(weights_stochastic))\n",
    "        y_hat =  sigmoid(-z)\n",
    "        y_hat\n",
    "        temp2 = y_hat-y[i]\n",
    "        temp = np.multiply(temp2,x[i])\n",
    "        weights_stochastic -= lr*temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Batch\n",
    "### For 100 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.rand(1,6)\n",
    "epochs = 10\n",
    "for i in range(100) :\n",
    "    y_hat = predict(x, weights)\n",
    "    y_hat = y_hat.reshape(1,len(x))\n",
    "    accuracy = 0\n",
    "    for j,val in enumerate(y) :\n",
    "        if y_hat[0][j] <=0.5 and val == 0 :\n",
    "            accuracy +=1\n",
    "        if y_hat[0][j]>0.5 and val == 1 :\n",
    "            accuracy +=1\n",
    "    weight_update(x,y, y_hat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Stochastic\n",
    "### For 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_stochastic = np.random.rand(1,6)\n",
    "epochs = 10\n",
    "for i in range(100) :\n",
    "    weight_update_stochastic(x,y)\n",
    "    y_hat = predict(x, weights_stochastic)\n",
    "    y_hat = y_hat.reshape(1,len(x))\n",
    "    accuracy = 0\n",
    "    for j,val in enumerate(y) :\n",
    "        if y_hat[0][j] <=0.5 and val == 0 :\n",
    "            accuracy +=1\n",
    "        if y_hat[0][j]>0.5 and val == 1 :\n",
    "            accuracy +=1       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_neg_pd + test_pos_pd\n",
    "test_labels = test_neg_labels + test_pos_labels\n",
    "c_test = list(zip(test_data, test_labels))\n",
    "random.shuffle(c_test)\n",
    "x_test, y_test = zip(*c_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998\n",
      "997\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "y_ = predict(x_test, weights)\n",
    "y_ = y_.reshape(1,len(x_test))\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for j,val in enumerate(y_test) :\n",
    "    if y_[0][j] <=0.5 and val == 0 :\n",
    "        TN +=1\n",
    "    if y_[0][j]>0.5 and val == 1 :\n",
    "        TP +=1\n",
    "    if y_[0][j] <=0.5 and val == 1 :\n",
    "        FN+=1\n",
    "    if y_[0][j] > 0.5 and val == 0 :\n",
    "        FP+=1\n",
    "print(TP)\n",
    "print(TN)\n",
    "print(FP)\n",
    "print(FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Stochastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "999\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "y_ = predict(x_test, weights_stochastic)\n",
    "y_ = y_.reshape(1,len(x_test))\n",
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "TN = 0\n",
    "for j,val in enumerate(y_test) :\n",
    "    if y_[0][j] <=0.5 and val == 0 :\n",
    "        TN +=1\n",
    "    if y_[0][j]>0.5 and val == 1 :\n",
    "        TP +=1\n",
    "    if y_[0][j] <=0.5 and val == 1 :\n",
    "        FN+=1\n",
    "    if y_[0][j] > 0.5 and val == 0 :\n",
    "        FP+=1\n",
    "print(TP)\n",
    "print(TN)\n",
    "print(FP)\n",
    "print(FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (for 2000 dataset examples):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Batch Gradient Descent| Pos | Neg |\n",
    "| --- | --- | --- |\n",
    "| Pos | 998 | 3   |\n",
    "|Neg  | 2   | 997 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Stochastic Gradient Descent| Pos | Neg |\n",
    "| --- | --- | --- |\n",
    "| Pos | 1000 | 1   |\n",
    "|Neg  | 0   | 999 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent  \n",
    "### Precision = 99.7%\n",
    "### Recall = 99.8%\n",
    "### Accuracy = 99.75%\n",
    "### F1-score = 0.499"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent  \n",
    "### Precision = 99.9%\n",
    "### Recall = 100%\n",
    "### Accuracy = 99.95%\n",
    "### F1-score = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
